import pickle
import torch
from torch.utils.data import Dataset
import numpy as np

class SparseMolecularDataset(Dataset):
    """
    Dataset for sparse molecular graphs with 'adjacency' and 'node_features'.
    Each sample returns:
      - adj: FloatTensor [N, N, R]  (no self-loop channel)
      - feats: FloatTensor [N, T]
    """
    def __init__(self, path: str, subset: float = 1.0):
        raw = pickle.load(open(path, 'rb'))
        # Support both old and sparse dataset formats
        if 'adjacency' in raw and 'node_features' in raw:
            data_adj = raw['adjacency']
            data_feat = raw['node_features']
        elif 'data_A' in raw and 'data_F' in raw and 'bond_num_types' in raw:
            # Convert sparse dataset format to dense one-hot adjacency and feature arrays
            A_list = raw['data_A']
            F_list = raw['data_F']
            bond_num_types = raw['bond_num_types']
            # Stack and one-hot encode adjacency
            A_arr = np.stack(A_list)  # shape (N, N, N)
            data_adj = np.eye(bond_num_types)[A_arr]  # shape (N, N, N, R)
            # Stack node features
            data_feat = np.stack(F_list)  # shape (N, N, T)
        else:
            raise KeyError("Dataset file must contain 'adjacency'/'node_features' or 'data_A'/'data_F'")
        N = len(data_adj)
        cutoff = int(N * subset)
        self.adjacency = data_adj[:cutoff]
        self.node_features = data_feat[:cutoff]

        # Atom-type lookup used when rebuilding molecules.
        # Try multiple possible keys from the pickled dataset generated by different
        # preprocessing scripts and normalise to a list[int] whose length matches
        # the node‑feature one‑hot dimension.  If nothing is found, fall back to
        # the canonical QM9 ordering (C, N, O, F, H) and pad with hydrogen (1).
        decoder = (
            raw.get("atom_decoder")      # e.g. list like [0,6,7,8,9,1]
            or raw.get("atom_types")     # alternative legacy list
            or raw.get("atom_decoder_m") # dict {idx: atomic_number}
        )
        if decoder is None:
            decoder_list = [6, 7, 8, 9, 1]  # C, N, O, F, H
        else:
            # Convert dict or list/tuple to list ordered by index
            if isinstance(decoder, dict):
                decoder_list = [decoder[i] for i in sorted(decoder)]
            else:
                decoder_list = list(decoder)

        # Guarantee index 0 corresponds to PAD (atomic number 0)
        if decoder_list[0] != 0:
            decoder_list = [0] + decoder_list

        # Ensure list is long enough; pad with H (atomic number 1) as needed
        feat_dim = self.node_features.shape[-1]
        if len(decoder_list) < feat_dim:
            decoder_list.extend([1] * (feat_dim - len(decoder_list)))

        self.atom_types = decoder_list

    def __len__(self):
        return len(self.adjacency)

    def __getitem__(self, idx):
        adj = torch.tensor(self.adjacency[idx], dtype=torch.float32)
        feats = torch.tensor(self.node_features[idx], dtype=torch.float32)
        return adj, feats